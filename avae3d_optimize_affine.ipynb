{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Affine Variational Autoencoder\n",
    "\n",
    "Add optimization of rotations and translations into the VAE, done before each forward pass\n",
    "\n",
    "**Goal: Show that this optimization results in lower reconstruction loss, and that is gives a more disentangled representation of orientation and shape**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import matplotlib\n",
    "matplotlib.use('pdf')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from IPython.display import display, HTML\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "import kaolin as kal\n",
    "from kaolin.datasets import ModelNet, ModelNetVoxels\n",
    "\n",
    "from models import *\n",
    "from dataset.trans_model_net_voxels import TransformedModelNetVoxels\n",
    "from utils_3d import pad_for_transform, make_affine #affine_transform, get_affine_matrix\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "device = 'cuda:0'\n",
    "modelnet_path = './data/ModelNet10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-dd738ec8370b>, line 43)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-dd738ec8370b>\"\u001b[0;36m, line \u001b[0;32m43\u001b[0m\n\u001b[0;31m    if self.opt_method in ['all_90_rot', 'rand_sgd_rot'] or : # inverse is transpose if rot\u001b[0m\n\u001b[0m                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, random_split, DataLoader\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class AVAE3d(nn.Module):\n",
    "    def __init__(self, VAE, opt_method='all_90_rot'):\n",
    "        super(AVAE3d, self).__init__()\n",
    "        assert opt_method in ['none', 'all_90_rot', 'rand_sgd_rot', 'rand_sgd_rot_trans']\n",
    "        self.VAE = VAE\n",
    "        self.opt_method = opt_method\n",
    "        if self.opt_method == 'all_90_rot':\n",
    "            self.all_90_rot = self.get_all_rot_mat()\n",
    "            \n",
    "    def get_all_rot_mat(self):\n",
    "        def rot90_x(mat): return torch.mm(torch.FloatTensor([[1, 0, 0], [0, 0, -1], [0, 1, 0]]), mat)\n",
    "        def rot90_y(mat): return torch.mm(torch.FloatTensor([[0, 0, 1], [0, 1, 0], [-1, 0, 0]]), mat)\n",
    "        mat = torch.zeros(3, 4)\n",
    "        mat[:, :3] = torch.FloatTensor([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
    "        all_rotations = []\n",
    "        for cycle in range(2):\n",
    "            for step in range(3):\n",
    "                mat[:, :3] = rot90_x(mat[:, :3])\n",
    "                all_rotations.append(mat.clone())\n",
    "                for i in range(3):\n",
    "                    mat[:, :3] = rot90_y(mat[:, :3])\n",
    "                    all_rotations.append(mat.clone())\n",
    "            mat[:, :3] = rot90_x(rot90_y(rot90_x(mat[:, :3])))\n",
    "        return torch.stack(all_rotations)\n",
    "            \n",
    "        \n",
    "    def affine(self, x, affine_params, padding_mode='zeros'):\n",
    "        grid = F.affine_grid(affine_params, x.size(), align_corners=False).to(x.device)\n",
    "        x = F.grid_sample(x, grid, padding_mode=padding_mode, align_corners=False)\n",
    "        return x\n",
    "    \n",
    "    def affine_inv(self, x, affine_params, padding_mode='zeros'):\n",
    "        print('affine_params.size()', affine_params.size())\n",
    "        if self.opt_method in ['all_90_rot', 'rand_sgd_rot'] or : # inverse is transpose if rot\n",
    "            zeros = torch.FloatTensor(affine_params.size()[:, :, 1]).fill_(0).to(x.device)\n",
    "                inv_affine_params[:, :, :3] = torch.cat([torch.transpose(affine_params[:, :, :3], 1, 2), \n",
    "                                                        zeros])\n",
    "            print('zeros.size()', zeros.size())\n",
    "            print('inv_affine_params.size()', inv_affine_params.size())\n",
    "        else:\n",
    "            pass\n",
    "        grid = F.affine_grid(inv_affine_params, x.size(), align_corners=False).to(x.device)\n",
    "        x = F.grid_sample(x, grid, padding_mode=padding_mode, align_corners=False)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def forward(self, x, deterministic=False):\n",
    "        if self.opt_method=='none': # affine is identity\n",
    "            affine_params = torch.zeros(3, 4).to(x.device)\n",
    "            affine_params[:, :3] = torch.FloatTensor([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
    "            affine_params = affine_params.unsqueeze(0).repeat(x.size(0), 1, 1).to(x.device)\n",
    "            recon_x, mu = self.affine_forward(x, affine_params=affine_params, deterministic=deterministic)\n",
    "        elif self.opt_method=='all_90_rot':\n",
    "            recon_x, mu, loss, affine_params = self.forward_best_90_rot(x, deterministic=True)\n",
    "            # Shouldn't need this:\n",
    "            recon_x, mu = self.affine_forward(x, affine_params=affine_params, deterministic=False)\n",
    "        elif 'rand_sgd' in self.opt_method:\n",
    "            recon_x, mu, loss, affine_params = self.forward_opt(x, deterministic=True, n_sgd=4, n_total_affine=16)\n",
    "            recon_x, mu = self.affine_forward(x, affine_params=affine_params, deterministic=False)          \n",
    "        return {'recon_x':recon_x, \n",
    "                'mu': mu,\n",
    "                'affine_params': affine_params}\n",
    "        \n",
    "        \n",
    "    def affine_forward(self, x, affine_params=None, deterministic=False):\n",
    "        x_affine = self.affine(x, affine_params)\n",
    "        mu = self.VAE.encode(x_affine)\n",
    "        z = self.VAE.reparameterize(mu, deterministic)\n",
    "        recon_x = self.VAE.decode(z)\n",
    "        recon_x = self.affine_inv(recon_x, affine_params)\n",
    "        return recon_x, mu\n",
    "\n",
    "    \n",
    "    def forward_best_90_rot(self, x, deterministic=True):\n",
    "        \"\"\" Try all 24 rotations.\n",
    "        \n",
    "        Loss for all afffine params and imgs in parallel. \n",
    "        Duplicate imgs & params since can only apply one affine per img.\n",
    "        returns: loss, affine_params(3x4)\n",
    "        \"\"\"                                \n",
    "        with torch.no_grad():\n",
    "            affine_params = self.all_90_rot.clone().detach().to(x.device) # be safe\n",
    "            bs, ch, _, _, _ = x.size()\n",
    "            n_affine, _, _ = affine_params.size()\n",
    "            x_repeated = x.repeat(n_affine, 1, 1, 1, 1)\n",
    "            affine_params_repeat = affine_params.repeat(bs, 1, 1).view(bs*n_affine, 3, 4).to(x.device)\n",
    "\n",
    "            recon_x, mu = self.affine_forward(x_repeated, affine_params=affine_params_repeat, deterministic=deterministic)\n",
    "            loss = self.vae_loss_unreduced((recon_x, mu), x_repeated)\n",
    "            loss = loss.view(n_affine, bs, 1)\n",
    "            best_loss, best_param_idx = torch.min(loss, dim=0)\n",
    "\n",
    "            # select the params, recon_x, mu corresponding to lowest loss\n",
    "            mu = mu.view(n_affine, bs, -1)\n",
    "            affine_params_repeat = affine_params_repeat.view(n_affine, bs, 3, 4)\n",
    "            recon_x = recon_x.view(n_affine, bs, 1, recon_x.size(-3), recon_x.size(-2), recon_x.size(-1))\n",
    "            recon_x_best = recon_x[best_param_idx.squeeze(), torch.arange(bs), :, :, :, :]\n",
    "            mu_best = mu[best_param_idx.squeeze(), torch.arange(bs), :]\n",
    "\n",
    "            best_affine_params = affine_params_repeat[best_param_idx.squeeze(), torch.arange(bs), :, :]\n",
    "        return recon_x_best, mu_best, best_loss, best_affine_params\n",
    "\n",
    "    def forward_opt(self, x, deterministic=True, n_sgd=4, n_total_affine=16):\n",
    "        \"\"\" BS=1 !\n",
    "        n_affine is number of random restarts\n",
    "        \"\"\"\n",
    "        bs, ch, _, _, _ = x.size()\n",
    "        assert bs==1\n",
    "        r_init = torch.ones([n_total_affine, 3], dtype=torch.float32, device=x.device).uniform_(0, 2*math.pi)\n",
    "        if 'trans' in self.opt_method:\n",
    "            t_init = torch.ones([n_total_affine, 3], dtype=torch.float32, device=x.device).uniform_(-.2, .2)\n",
    "        else:\n",
    "            t_init = None\n",
    "\n",
    "        with torch.no_grad():\n",
    "            affine_params = make_affine(r=r_init, t=t_init, device=x.device)\n",
    "            x_rep = x.repeat(n_total_affine, 1, 1, 1, 1)\n",
    "            recon_x, mu = self.affine_forward(x_rep, affine_params=affine_params, deterministic=deterministic)\n",
    "            loss = self.vae_loss_unreduced((recon_x, mu), x_rep)\n",
    "            best_loss, best_param_idx = torch.topk(loss, k=n_sgd, largest=False)\n",
    "            \n",
    "        # SGD TIME - Select best params and get rid of old params so no grad or memory issues\n",
    "        del recon_x, mu, x_rep\n",
    "        r_init = r_init[best_param_idx, :].clone().detach().requires_grad_(True)\n",
    "        if 'trans' in self.opt_method:\n",
    "            t_init = t_init[best_param_idx, :].clone().detach().requires_grad_(True)\n",
    "        else:\n",
    "            t_init = None\n",
    "        x_rep = x.repeat(n_sgd, 1, 1, 1, 1)\n",
    "        \n",
    "        optimizer = optim.Adam([r_init, t_init], lr=.03)\n",
    "        for i in range(20):\n",
    "            affine_params = make_affine(r=r_init, t=t_init, device=x.device)\n",
    "            recon_x, mu = self.affine_forward(x_rep, affine_params=affine_params, deterministic=deterministic)\n",
    "            loss = self.vae_loss_unreduced((recon_x, mu), x_rep)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        affine_params = make_affine(r=r_init, t=t_init, device=x.device)\n",
    "        recon_x, mu = self.affine_forward(x_rep, affine_params=affine_params, deterministic=deterministic)\n",
    "        loss = self.vae_loss_unreduced((recon_x, mu), x_rep)\n",
    "        best_loss, best_idx = torch.min(loss, dim=0)\n",
    "        return recon_x[best_idx, :, :, :], mu[best_idx, :], best_loss, best_affine_params\n",
    "            \n",
    "\n",
    "    def vae_loss_unreduced(self, output, x, KLD_weight=1):\n",
    "        recon_x, mu  = output\n",
    "        BCE = F.binary_cross_entropy(recon_x.squeeze(), x.squeeze(), reduction='none')\n",
    "        BCE = torch.sum(BCE, dim=(1, 2, 3))\n",
    "        KLD = -0.5 * torch.sum(1 + 0 - mu.pow(2) - 1)\n",
    "        return BCE + KLD_weight*KLD\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affine Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "converting to voxels to resolution 32: 100%|██████████| 200/200 [00:00<00:00, 31881.30it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-66f45d9be353>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'32'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mvisualize_affine_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maffine_objectives\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-49ddd0b39471>\u001b[0m in \u001b[0;36mvisualize_affine_opt\u001b[0;34m(x, affine_trans_dicts, device)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprojection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'3d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvoxels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_pad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfacecolors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medgecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'k'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Initial'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'large'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;31m#         ax.axis('off')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaolin/lib/python3.6/site-packages/matplotlib-2.2.5-py3.6-linux-x86_64.egg/mpl_toolkits/mplot3d/axes3d.py\u001b[0m in \u001b[0;36mvoxels\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2896\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mfilled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfilled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2897\u001b[0m                             \u001b[0mvoxel_faces\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msquare_rot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfilled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfilled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m                             \u001b[0mvoxel_faces\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msquare_rot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALkAAADbCAYAAAAxkTANAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi41LCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvSM8oowAAIABJREFUeJztvXl0W+WZP/65krxvkrVZ8m7HduzEu5OUllIylKEFhmkJhFCm2CwzB4bOAD2HQttzpuUfUpghJWeWfs8EOuQQlmbgTMOkDBTIj0NJA07i3Um8r5JsrZa1b/f9/WHuRVYkWcu1JDv6nOMDdqT3vpI+eu7zPs/neR6KEII00tjO4CV7A2mksdlIkzyNbY80ydPY9kiTPI1tjzTJ09j2SJM8jW2PNMnT2PZIkzyNbY80ydPY9kiTPI1tD0GUj09rANJIJVCRPChtydPY9kiTPI1tjzTJ09j2SJM8jW2PNMnT2PZIkzyNbY80ydPY9kiTPI1tjzTJ09j2SJM8jW2PNMnT2PaIVruSBgCapuFwOEAIQWZmJgQCAXi8tL1IVaRJHiVomobb7QZN0/D5fPB4PKAoCnw+HxkZGcjIyACPxwNFRaQdSiMBSJufKOD1euFyuQAAFEWBx+OxVpymafz5z3+GxWKBxWKBw+GA1+tFunlT8pG25BGAELLOagdaaf+/8fl8EELgcrngcrlAURRr4fl8ftqtSQLSJN8AhBB4vV54vd6gBA8Gxn1hnu92u+F2uwGsfQn8/fi0W7P5SJM8DAgh8Hg88Pl8ERM8EIGE9z+0+hOez+enCb9JSJM8BBgLTNN0zAQPhP86hBAQQuB0Otl/Y9wagUCQJjyHSJM8CJgICiGEM4IHInDdQLdGIBCsi9akETvSJA+AP8ETSa5AtyYdnuQOaZL7wev1YnJyEnl5eZDJZEnbB2PleTzeOj/e6XSybk1mZmbaj48QaZJjveX0+XygaTrZW2LhT3hgvVvjcDiQkZGBoqKidHgyDK55kgeGCBnrmarwd2tMJhObkALS4clQuKZJHixESFFUSpM8EDwej01AMW4N8/d0eHIN1yzJQ4UI4yU5E5FJBPyvlQ5PhsY1SfJwMfBISZ7KREmHJ9fjmiP5RiHCreSuRHrXCBae9Hq9cDgcrFuzncOT1xTJfT4f3G73umhFIOIhOfPcZLgrkSKYWxMYntxubs01Q3Kv1xtSRegPiqIiCiHqdDrQNI3i4mLWSm41hApPBqont3pRyLYnebQqwo0sOSEE09PTMJlMyMnJwczMDHJyciCVSlnLmChwfdcIdGs8Hg9759vKWddtTfJYVIThSE4IwZUrV+Dz+dDS0sI+zm63Q6fTwW63Y3BwEDKZDBKJBNnZ2Zy+nmD72SwEU086nU7Y7XaYTCYolUpWI5/qhN+2JI9VRRjqcTRNY2hoCHl5edi5cyd7eOPxeMjLy0NeXh4MBgMaGhpgMplw+fJl+Hw+SCQSSCQS5OXlbZrQa7MR6McvLi5CLBZvmaKQbUnyeGSywXxyr9eL/v5+yGQyVFZWhn1uVlYWysrKUFZWBo/HA4PBgJmZGTgcDhQXF0MqlaKwsJATcibykMuApmk2AcXsIdWLQrYdyeNVEQZ+KC6XC/39/aisrIRCoYhqrYyMDJSUlKCkpAQ+nw8mkwlqtRpXrlxBUVERpFIpRCJRSlq/UGBIzmArFIVsK5LTNM3eQmMljr8lt9vtGBgYQENDA8RicVx74/P5rOtCCIHZbIZOp8PU1BRyc3PZf2N0KJEgGZY83DVTNeu6bUhut9thNpshEoniegOZ566urmJ4eBi7d+9GUVFRxM+NNFsqFAohFApBCIHNZoNOp8PAwAAEAgGkUikkEgmysrJifh2bhUBLHgobZV1ff/113HfffRAKhZu2VwZbnuRMiNBqtWJxcRHFxcVxr2mz2TAyMoK2tjbk5eVxsMvQoCgK+fn5yM/PR3V1NRwOB/R6PUZHR0EIWXdwDUSqWfJwCHRr3nnnHdx1111cby8otjTJ/WPgXElkV1ZWYDKZ8PWvfz0mSxrvHnJyclBeXo7y8nK43W4YDAZMTU3B5XKxB9eCgoKk+beRWvJwoCgKTqcTubm5HO0qPLYsyQMjKIzcNB7Mz89Dp9NBJpPFRHCuiZeZmQmFQgGFQgGfzwej0YjFxUVYLBYIhUK4XK6E62y4IDkAOJ3OTc8jMNiSJA8WIow0HR9qvcnJSVitVjQ0NECr1XK84/jB5/MhlUohlUpB0zTMZjPGx8cxNjaGwsJCSKVSFBcXR3VwjQVcuUg0TW/6XhlsOZKHChEyrdqiBSEEly5dAkVRaGtrw8rKSsxS20QpGHk8HkQiEYRCIeRyOfh8PnQ6Hebm5pCZmckeXDMzMzm/NleWPJHYUiQPFyKMxSf3+XwYGhpCQUEBamtrt0T5mz+YL3pBQQEKCgpQU1MDu90OvV6PkZERAGAPrlz5v1xY8kRrfLYMyTdSEUbrrng8HvT390OhUKC8vHzdv8UjtU0kghEuNzcXFRUVqKiogNvthl6vx8TEBNxuN8RiMaRSKfLz82PeK5eWPFHvV8qTPFIVYTTuitPpRH9/P2pqaiCXy9f9Gxflb6mCzMxMKJVKKJVKeL1eGI1GzM/Pw2azQSgUQiKRQCgURkXatLvCMaKRyUZKTpvNhsHBQezcuTNoTH07VgYBayVvMpkMMpkMNE1jZWUFOp0OExMTKCgoYA+uG2njuXJXEomUJXm0IqtI3niz2YyRkRG0tLSgoKAg5DrxVgalOng8HoqLi1FcXAxCCCwWC3Q6HWZnZ5GVlQWpVAqxWBz04MqFJXe73QnN5qYkyTej2aZer8f4+Dja29vDHsK2ClEBbqwqRVEoLCxEYWEhamtrYbPZoNfrMTw8DIqi2EhNTk4Oe814SZ7IGDmQgiTfjGabGo0Gc3Nz6Orq2jCsFinJdTodrFYrZDLZug9sq3xBQoHRxldWVsLlckGv12NsbAxerxdisRherxf5+flxXcPhcFy7JN+MZpuzs7PQ6/Xo6uqKKPkQCckXFxehUqkgkUhw+fJl0DQNiUSS8PZym61dycrKQmlpKUpLS+H1emEwGDA7O8t+wZmDa7R7cDqd7J0hEUgZkvuHCLkgOCEEExMTcDgc6OjoiHjNjUg+OzsLg8GA9vZ20DTNakz0ej0sFguGh4fZA95mi7sSKdASCASQy+Ww2+3Izc2FQCDA8vIyxsfH2YyrSCSKqKj7mnNXNprHEwtomsbo6CgEAgFaWlqirgwKRnJCCKampmC1WtHe3s4WCABfhepMJhPKysrgcDjWiapkMllcselUApOOF4vFEIvFIIRgdXUVOp0O09PTbFG3WCxGRkZG0DWuKUseyzyejeDz+TA4OAihUIjq6uqY+pIEkty/gLm1tRUURcHn8wV9vkAgYKuBmNj03Nwc7Hb7tih/C7wmRVEoKipCUVERCCFsUffg4CCrtwks6nY6nddGdIWppO/t7UVXVxdnH/qFCxdQWlqKsrKymNYIJDlzV8jIyMCuXbui2qd/bJpREapUKly5cgUikQhSqTQmnzaZCBdCpCiKPbhWVVXB6XRCr9dfVdTtcDiisuQ+nw9dXV0oLS3F6dOnMTMzg0OHDqG3t3cSwEUAPySEuEM9PympKyZE6N/RKl44nU7YbDZUVVXFTHBgPclpmsbg4CByc3PR0NAQV88Wxqo1NTVhz549EIvFWF5eRm9vL65cuQKDwRD1wTWZhcyRIDs7G2VlZWhvb0drayuys7MxNTWFn/3sZ/jiiy/w+eefR7TO0aNH0djYyP7+9NNP48knnwQhZAcAE4CHwj0/4SQnZG3GJZcxcKvViosXL7K1kvGAIarX60VfXx+Ki4tZ8Vawx8UCHo8HsViMnTt3Yu/evZDL5TAYDDh//jwuXboEvV4f0h0Ktt9EItYvFlPU3draiieffBI1NTX49NNPN3ze4uIi/vCHP+Dhhx9mr3/mzBn/qqLjAL4Xbo2kuStchQhXVlYwOjqK1tZWXLp0Ke44NSP0unjxIsrKylBaWhr2sYGI9voURUEkEkEkErGHOK1Wi+npaeTm5kImk0EsFgeNWiQjJs9FxpNpzvSTn/xkw8c+8cQTeOGFF2CxWAAABoMBQqHQPxy8CCD0h4QkkDyYnDVW68BoLzo6OpCTkxNX4QQDt9sNm82GlpaWq8RbG4GL7KP/Ic5qtUKr1WJ2dpaNWvhX9KfCwTMWRBpdOX36NGQyGTo7O/HJJ5/EfL2khxAZwkf7xqlUKiwuLq7LYsZaOMHA4XCgv78fWVlZUROca1AUxerEmXS7VqvFwMAAMjIy2AqhRIMLS+50OiNq8XH27Fm8++67eO+99+B0OrG6uorHH38cKysr8Hq9zJe9DIAq3DpJ10zyeLyI/U8GMzMzWFpaQmdn57o0fTwkt9ls6OvrQ1NTU8xlWZupe8nLy0N1dTW6urpQV1cHj8cDq9WK4eFhLC4uwuVybcp1A8EVySNJBh0+fBiLi4uYnZ3FW2+9hb/4i7/A66+/jv379+Ptt99mHtYN4FS4dZJOcj6fHzExmXi1xWJBe3v7VWSMlWSrq6sYGBhAS0tLQvqAxIvc3FxUVlaioKAA9fX1IIRgdHQUfX19WFhYYBv6bAa4cFdcLldcGc/nn38eR44cAUVRkwDEAF4J9/ikuCv+ZIzUktM0jZGREWRlZaG5uTnoGx2LJTeZTLh06RInPVaS4R/n5OQgPz8f5eXlrKDKX08jlUo5bf3AhSWPNk4OADfeeCNuvPFGAEBNTQ16e3sBYEckz00Jn3wjYnq9XgwODkIsFqOqqirsWtFYckZ+yxxcuUAy+5P7C6o8Hg97MHe73Szh4+2uy5Ulv2bS+sCauxLOkrvdbvT396O8vBxKpTLsWtFEV5aXlzE9PR2R/HYrIiMjY13pm16vx8zMDJxOZ1x6Gia/EQ+uOaltOEvORDvq6uoglUrjWssfKpUKKpUKXV1dIUVEsSDRBReRWlV/PY3P54PBYGBrPUUiEWQyWVR6mrQljxKhiGmxWDA0NIRdu3ZFfBiMxF2Zm5uDXq9HZ2fnlp31Ew/4fP46PY3JZIpKT8OVBGPbW3L/NyqYu8IcBltbW6OqQgnnrjCzfpjIDFea9cDrJzoLGQ/p/NtJM8XNjEZ8M/unJ7IPIpCCllyr1WJqagqdnZ1Rf9tD3RUIIWwJFyOVjQdM1y2DwcDe7rdC6DEcAoubmWr+qakp5Ofns9X8XOCasOT+8Cfm4uIi1Gp1zL5yKC04U0ARrVQ2GJhQZnZ2Nvbt2wez2QytVouJiQkAaxGOrSafDUQwPY1Op2MPrlqtNq6+i9ecJefz+fB6vZiamoLZbI7LVw605Mwwq/z8/KBKwmjBrFdQUIDq6mp4PJ51ZBgdHYXJZIJGo4FQKGQt/FYnvL+e5vPPP4fVasXc3ByysrLYSXfREP6asOSBlSVqtRp5eXloa2uLy//zJ7nP58PAwMCGsfVIQdM0BgYGIBKJUF1dfZVbRFEUsrOzUVxcDKFQuM6/3U6EFwgEqKmpQU1NTVA9TSSNRhPZ0RZIsiWnaRoqlQp8Pp8TV4JxV5g+h0xiJF4wXxiJRBJ2+hsDf/828EC3lQkf6AoyehpmQoZWq8Xw8DB4PB7bZjoVRsIkjeTM2MD8/HxkZ2dz8oHzeDy4XC5cvHgRVVVVKCkpiXktJgbN7LOkpOSqxqCBCHYmCEd45tBaVFS0JQgfLi6fk5ODyspKVFZWwul0QqfTYXR0FADYbGtOTk5U0Sen04kbbrgBLpcLXq8Xd911F5599tmoy9+SQnKXy4ULFy6gsrISAoEAJpOJk3W9Xi8WFhawe/fuuCqEGLL6fD709fWFvCNEm+IORniNRoOxsbEtQfhIdSvZ2dnrRsLodDo2uqXRaJCZmRnRa8zKysKZM2eQn58Pj8eD66+/Ht/97ndx5MgRPPnkkzh06NAOiqL+H9bK334Tap2kqBCtVivq6uqgUCg2TOtHCpvNhrm5OdYvjAcURcHj8eDixYsoLy8P6fLEUxLHEL6xsZGt+dRoNOjt7cX4+HjEwwASiVhS+pmZmSgtLUVbWxtaW1tht9uxsLCAvXv3YmFhIexzKYpi8yQej4dtWxJt+VtSSC6RSFjRfLyFDsBadnRgYAAVFRWc+ICEEPT19aGqqirkgFourS1T8xmK8GazOSUIH29ns4yMDNx9992Qy+X46KOPNtQiAWvnoba2NshkMtx8882ora1N/fK3QESjJw8Gpsazra0NdrsdKysrce3H5XLBarWiubk5KdVBDOHFYjFoml43xZkRVnHVtyVacNXRNjMzE4WFhRE9ns/nY2BgACsrK/j+97+PK1euRH3NpJM8lsogBgaDAWNjY6xU1uFwxPWFcTqd6OvrQ15eXkzZPa7T+oGE9+/bUlxcDJ/Pl9A6T67qO2OJkQuFQuzfvx/nzp3bmuVvsRCTiVB0dnayirZ4XB+Hw4G+vj7s3LkzJaW3PB4PEomE7dsiEongdrvR29uLiYmJhLg0XBVMREpynU7H3pkdDgc+/PBDNDY2Rl3+lvRkUCwHT7VajYWFhavS/7EOtbLb7ejv72cVjzMzM3GNS9xsMITPyclBZ2cna+GZKI1cLt+UgbZcaMmj6YOo0WjQ3d0Nn88HmqZx8OBB3H777WhqasKhQ4dw7733TgLoRyqWv/kjWus7Pz8PrVaLzs7OoDWe0ZLTZrNhYGAAu3fvRlFRUVTPDUQy/GSG8IySkBloa7VaWR+eK8InugF/S0sL+vv7r/r7tix/A76Syq6uroZsxRztF8ZqtWJwcBDNzc3rDkKR3hGS0fckHPwJz/ReXFhYgM1m44TwXFXqJ7JgAkgRkm9EKEIIxsfH4Xa70draGvKNjobkTFFGKM16LANrU2kUi/8EZ64In8yDZzxIuk++ERjtNo/Hw+7du8M+N1KSMQOyQlXopxJZucBGhJfL5RHVeyay5wqXSLolDweapjE8PIzc3Fzs2LFjww8hEkvOxNXDDciKleRb4csRjPBMvadYLA5b4JysdhTxImVJHotUdiPXx2g04sqVKxu2oIiErMxkBYlEctVwrK2CQMIbDAZ2YEAwwm/FdhRAEkkejkhM22SlUhlVr/Fw0RX/xNFGhNyI5ExZ2M6dO7GysoJLly4BWEtbi0SiiPebSggscA5GeJ/Pl9A4OVdIOUvudrtZ3Ui0UtlQ7opOp8Pk5CQ6Ozsj0raEIzmzVkdHB4A1TXVpaSlcLhfGxsawsLAAvV4PmUwGqVTKacuLRCEU4c1mM/Ly8iASiWJuUnTN+uSMBWYaCe3YsSOiPiuBCOauLC8vY2Zm5qrmoBvtJxjJ/b8sGRkZcLu/kjBnZWWta+mwvLyMgYEBtkOuRCLhtAVGonx/f8LPz8/DbrdjZmYGDoeDddWiIXykHW25REqQnMfjwWq1YmRkBI2NjTHf8gPJqdFoMD8/z5Iy1nWA9QTPzMwMSTKmP2FVVRWqqqpgs9mwvLyMubk55ObmQi6XQywWc97mIVEQCoVskyKmK1c0hL+mLLk/kQghGBoaQktLS8TqtI2gVquxuLgYNDMazd6Ar3zwje4GwT7cvLw81NTUoLq6GlarlW1PV1hYCJlMFnNfk2Q34Ofz+ZDL5ZDL5ewgW6aa3//QGoh4O9rGgqRbcrPZzM7G5IrgCwsLWFpaQkdHR0wFs/4kZwje0dERl3ArsKm+2WzG8vIyJicnIRQKIZfLo64KSpWhWMwg21CEl8vlbD4i0hDiwsIC7r//fiwvL4OiKPzd3/0dHn/8cRiNRtxzzz2YnZ3F5OTkhwAOEkLClpYlleRMxEMkEnFW8Op2u6HVatHR0RGzD8yQPFqCRxonpygKQqEQQqHwqjI4JjmzUTYyGfH4SO4egYTX6/Xs4N7s7GyYzeaISC4QCPDiiy+io6MDFosFnZ2duPnmm/Hqq6/ipptuwjPPPAOKoj4G8AyAp8OuFc2L5BKMFevs7MT4+Dgno0FmZmbg9XrjbgNHURRWVlag1+vjtuAbIbDu0z8byfi5oWQHqWLJQyFwcG9fXx96e3tx7tw5HD58GN/7XuiqNYVCwVZlFRQUoLGxESqVCqdOnfKfH3QcwCdIVZJ7PB5WKstFCdzU1BQsFgtycnLiPtTZ7XZYLBbs27cvodryQIGVXq/H9PQ0XC4XpFIpZDJZQjtPBSKejKdAIMDevXvR0tKCRx99FNXV1RE/d3Z2Fv39/di3bx+Wl5f9SxKXAGxYvpU0kpeXl7M68niKmQkhmJychMPhQEtLS8QDUENBq9ViZWUFdXV1UROci+lzDAIPdjqdDuPj4/D5fGxfwq06+U0qlUac5LNarThw4ABeeumlq85shBBCUdSGflvSD55A7BU9jDrR4/GEHLESDZj5mUqlMqXaOgsEAvb27d/iwWazYXFxETKZLCF3nERLbT0eDw4cOID77rsPd955JwBALpdDo9FAoVCAoigFAO1G66REsDaWYmZmSJbP57uq+1YshzKG4ExEJtaD3WYfCJkWD83NzcjPz2dFbAMDA9BoNPB6vZt27UTO8CSE4KGHHkJjYyN+/OMfs3+/4447cPz4cebXDUvfgBSy5NG4K/6danfu3HlVb8VoPwx/gjONb2JVISYSfD4fFRUVqKiogMPhwPLy8ro5pFxnWRNpyc+ePYvXXnsNzc3NaGtrAwA899xzeOaZZ3Dw4EG88sorAPBtAAc3WiupySAG0bgrhBAMDw8jOzsbdXV1VxEr2jrPQIIze0t1yWzg/vyzrMwk57m5OeTl5bGjy+MlaCL15Ndff33Iz+Djjz9m/vfbkVwzJSx5pO6Kf+vk2traoI9hDn+RWLBgBGfWSHU9ebi7VX5+PvLz81FdXQ2LxbIuyyqXyyEUCpOWZU10R1sgRUjO4/Hg8XjCPoamaQwODkIoFIYNP0V6V2AIHkzXshUseSSgKAqFhYUoLCwEIYTNsk5MTMSUZeXCkicDKUPycMSMpnVyJO5KOIIDW4Pk0VrVcFlWRmsSSZY1HkuerPc0JXzycHFyn8+H/v5+yOXyDVsnM+uG+8JsRPBI1gDWNC2XLl1CUVER5HI5G7dOBXdlIwRmWZmRh3a7HRKJZJ3WxB9cWfJEH9BT2pIzqeBomumHuytEQnBgY0tuMBhYVaLD4WA1LpmZmcjNzU25VhXh4N8wn8myMloTqVQKuVzORkO20uvyR8qS3OPxoK+vL6JJzIFrBSNopAQHwpPcaDRibGwM7e3tIIQgLy8Pubm5qK6uxuzsLIxGI86fPw+xWIySkpKgFpELbAbh/LOsHo8Her0eY2Nj8Pl8kMlkcXfQuubcFX8EuivxlMAFczWiITizRrAPxGQy4cqVK2hra4NAIFjXrN/n8yErKwsSiQRlZWUwGo2YmpqC2+2GTCaDXC5PidEikSIjI2NdllWr1bINUeVyOaRSadRZVrfbnZT3ICVI7m/J3W43Ll68iNraWshksrjWAqInOBCc5GazGZcuXUJbWxsyMjJAURT7w+Px4HA4oNFo2N4wYrGYnYmp1+sxOjoKiqJYgsRb+5lI1yEzMxNlZWXQaDRoamqCVqvF0NAQK6uVSqURhQWdTue1RfLAgydN03C5XOjr60NdXV3M0yL8CRoLwQPXAIDV1VWMjIygtbWVzYj6799qtbI90nNyckDTNGvhaZpmayQ9Hg90Oh0GBgaQnZ3NlsKlkk5mI2RnZ7NZVrvdDq1Wi/7+fmRnZ7PjDkO9nmT0XAFSyJIzFryhoSGuQlfGksdKcGA9yS0WC4aHh9HS0oKsrKyrCG6z2dh/928hDXz15SWEwOv1si5AaWkpS5DZ2VkUFBRALpdDJBJFbJ1T4RCYm5u7LsvK1LLm5eWxESf/aEwy6juBFCG5y+XC6uoqurq64u5bwuPxYDQaYTQaYyI48BXJrVYrhoaG0NzczE6o8yeWw+HA0NAQdu/eHfKAGUh4xroz09KqqqqwurrKTnUuLi5GSUnJhm3bUoHk/mCyrDU1NWyWdWpqis2yikSiqBSIDz74IE6fPg2ZTIaRkREAWFf6VlVVhY8++ki0UekbkAIqRMYSZmdnc9KYx263Y3l5OWaCA2skd7vdGBwcxO7du5GTk3MVwZ1OJwYHB7Fr1y4UFBREtC6Px0NGRgaysrKQmZnJ3tYZmUJHRweKioowNzeHCxcuYHZ2Fg6HI6bXkCwwWda6ujrs3bsXCoUCOp0Ovb29eOWVVyKeBtLT04P3339/3d9+9atf4aabbsLExARuuukmYK30bUMkjeQURcFqtbK9wbnwS7VaLUwmE6qqquI62DHRhF27diE3N/cqgrtcLgwMDGDnzp0xF1+HIrxQKER9fT1aW1uRlZWFsbExXLx4EYuLi+v6vCTakseq5REKhWhoaMCePXtQUVGB8fFx3HrrrRs+94YbbrhqpM2pU6fQ3d0NAMx/w059Y5DUYbVMG4pILWE4MD54eXl5XFk5p9OJycnJdV2i/MnkdrsxMDCA+vp6CIXCuPcNrBGex+OBz+evO7CKxWJIJBK2IHh4eJiNaEQ6C5MrxPul4vF4aG5uxi233IJf//rXMa3hX/r2ZWg5osllSSO5QCDAvn37OLPgzCFTrVbHnHRg4sCVlZVQqVRYWVlZ50J5PB4MDAygpqYmpsFZGyHUgZUpCFYoFHA6ndBqtZiZmQFFUTAYDDH3bokGXHa05eLL+eUaEX3QST14xlOBwyAwihJrKR0TvmxoaEBBQQFycnJYARNTRDw+Po7KysqYWthFi0DCMz9ZWVkoLy9HYWEhlpaWYDAY2N4tJSUlmzb+kKuqoHgKsf1L3zQaDRBB6RuQAgfPeBAsTBgLyZkMa319PQoLC9nRgrt27cLevXuRm5uLvr4+uFwuuFyudb5xIsDj8SAQCJCZmcn676urq8jJyUF1dTU6OzshFouhUqlw/vx5TE9Pw2azcboHrgom4kkG+Ze+ffnfDUvfgBQJIcaCUHHwaJWAjEamtraW1VYHltMtLy+jrq4OUqkUS0tLGBgYQEZGBpRKJeclZhuBx+NBq9XCYrGgpaWF9eELCwtRVFQEQghMJhPnkgIuLHk0yaB7770Xn3zyCfR6Pcqxw36AAAAa+klEQVTKyvDss8+uK337UnL9q0jWSimSR/pG+neqDYyiRGPJGZVjdXU1m4jxvz5TJCwWi1kVJJPts1qt0Gg0mJ6eRlFRERQKBYRC4aYfBhlZrH8LvIyMDFY/Q9P0OhltoKRAJpPFVJnDhSV3uVwRJ/refPPNoH/3K30DAGMkayWV5P5WlxFpbfQBhCM4EDnJGYJXVFSwWvDAiv/R0VEUFhaioqLiqufn5+ejrq4OO3bsWDcaXCqVQqFQbIr6cHV1FRMTE0F7PPL5/HUHVkbwxlhyl8sFnU7HpuBLSkqiqvvcqpPfgBSy5JGQcyOCA5G5K0whRmlpKSQSSVCCX758mfV5w4GiKNZy+nw+tgmQx+NhW6Rx0RPFbrdjdHSU1c+EQqgDK9PKoqysjJUUzMzMoKCgACUlJRvehbgapXJNCbQCsRHJIyF4JOswBFcoFJDJZEEJPjY2BoFAELJYOhT4fD5LbLfbvc5/VygUkEqlMfnvLpcLQ0NDbHIqUjDxdwBXSQoqKipYSQFT9xluEhxXIcRktLlLGZKHK4GLlOBA+BpPmqYxMDAAmUzG6tQDCT45OQlCSNB2F9EgMzOT9d9tNhs0Gg1mZmai9t+9Xi8GBwdRV1cXV2vrYIT3+XxsO2lgTRsyOzvLtnLjuiooGb3JgRTwyRmEssDLy8uYnZ2NquAh2DpMtb9YLIZSqQw6QntmZgZutxtNTU2cHiDz8vKwY8cO1NbWRuW/My04KioqOB1BwhA+1IGV0cBfuXIFhBC2Dd1WHG8IpJglDyQnQ/COjo6ItSjBvizMJIuioiKUlZUFJfjc3BysVisnPRVDIRr/nTn4SiSSqKujokGwAytN02zdJ9NsdHp6GoQQFBQUxBw2vSYtuT8CW8XFQnBmHX93hem4lZ+fj4qKiqAEX1hYgMlkQktLS8L0IBv57yaTiS1QSARCHViZZqOZmZlYWVmBzWZjNeMlJSVRSQrS0RU/CxwrwYH17gpjDbOzs1FVVRWU4Gq1GjqdDq2trUlrnBPov1++fBkWiwUymQxGozGqYgouEMx/X1lZQX5+PmQyGZsn0Gq1rJhNLpdvKCmIN60fK1LGJ2csSDwEB776sjBhQIFAgOrq6qAEX1pagkajQVtbW8qUoJnNZvD5fNxwww0wm83r9DObFX8PBx6PB7VaDZ/Ph7KyMpb0eXl5qK6uRk1NDUwmExYXF9npGCUlJUHJfE1XBgFfVfSYzeaYCc6sQ9M0xsbGAIANAwYSXKfTYWFhAe3t7SlDcL1eD5VKxc47SkT8fSMYDAZoNBp2T3w+HxkZGaBpGl6vFzRNs525mMdPTEzA4/GwGVYmNh6rJX///ffx+OOPw+fz4eGHH8Yzz0RUK8EiZUhus9lgMplw3XXXxV3JbrPZkJOTg/r6egBXd2xippO1t7cnvPlkKJjNZnbSc+CXbrPi7xvBZrNhYmIiqCHg8XjIzMy86sAqFoshFovZRkWMpIDP58Pj8URtyX0+Hx577DF8+OGHKCsrw549e3DHHXegqakp4jVSQoW4vLwMk8mE8vLyuAk+NzcHn8+3juD+JDeZTJicnGRbS6QCbDYbLl26tGE2E/jKf9+7dy/q6+thtVrR29uL0dFRGI1Gzhr4uN1uDA8PY9euXWGzlEyxB6OQFAgE7N9kMhlaWlpQX1+PoaEhzM7O4gc/+AFmZmYi3kdvby927NiBmpoaZGZm4tChQzh1KiLx4Vd7jOrRmwDGB6+qqor7cDU9PQ273c7GfwMJbjabMTY2hra2toQOvAoHl8uF4eFhtpY0GjDx96997WtQKpVYWlrC559/jsnJybiktkx8vra2NqqqrUBJMHOXzMzMxMGDByGVSvHTn/40qooqlUq1rgdmWVkZVCpV5C8GKTDHkzlkGgyGuD6Y2dlZmM1m7Nq1iy0ELiwsRGlpKYqKimC1WnH58mW2djIV4PF4MDg4iPr6+rhKACmKgkgkgkgkYt2EWP135sAuk8niKg4JjND86U9/wurqKlpaWhJ+BkoqyYVCIXvIjGfM4dzcHIxGI5qbmwEA1dXVqK6uZk/9ly5dgsfjWdcbJdlgrGVlZSWnpXT+/QwZ/31wcJCNd2/kv8/OzoLH40XUQThSqFQqPP300/jzn/8cNcFLS0uxsLDA/r64uBhx81cGVJQ+HKcdG2maZpvv6/V6GAwGNDQ0RLXGwsICtFotWlpaAFztg9vtdgwMDKCkpARGoxE8Ho8VZyUrqsIkqEQiEadkCgdGP6PT6VBYWAiFQnFV/H15eRkqlQptbW2c5QxsNhtuv/12/PM//zNuuOGGqJ/v9XpRX1+Pjz/+GKWlpdizZw/eeOMN7Nq1CwAi8m9TI7SA2GZ5qlQqLC0tobW1FcDVBGea/zQ3N6OgoAA1NTWw2+1Qq9Xo7e1FUVERSktLN60uMhgYlWNubm7CCA6s18/4N+CXSCRQKBSgaZoVwXFFcJqm8dhjj+HBBx+MieDAWh3wv/3bv+GWW26Bz+fDgw8+yBA8YiTVkhNC2HpJs9mMhYUF7N69O6LnajQaLCwsoK2tbV3zTQYulwv9/f1obGxEUVFR0GsbjUao1WrYbDa2Gn6z/fWZmRk4HA40NjYmvQMW478vLi5iZWUFlZWVqKio4OxQfuTIEahUKvzHf/zHZr3WrWfJI/XJl5aWMD8/z46+C9UbpaGhISjBmecwMV2Px4Pl5WW2U6tSqYRUKuU8za9SqWA2mxOqkQkHPp8PsViMubk5NDc3s13BIvXfw+GDDz7Axx9/jA8++CDprzVlLLndbmeb24cDU8DMpOIDCe7xeNDf34/a2tqY5Kk2mw1qtRp6vR4ikQhKpXLDWTqRQKfTYW5uLqUyrIQQDA4OQi6X+8+rj8h/D4exsTH09PTgww8/jKn9dhSIaEMpQ3Kn04nR0VF0dnaGfLxer1+XgQskuNfrRX9/P6qqquLujUIIgcFggFqthsPhYENxsbgzKysrGBsbi0uusBkYHx8Hj8fDjh07gv47IYT1381mM+u/5+fnh1xzZWUFt99+O15++WV0dHRs1tYZbC93hdFEhLLgPp8Pg4ODKC8v56T5D0VRkEgkkEgk8Hg8WFpawtDQ0LpWFJG4M0x8vr29PaUIrlKp4HQ62bBrMASLv09OTsLtdgeNv3u9Xjz00EN46qmnEkHwiJFUSw6sHRCBNZKeP38eX/va1656jMlkwuXLl6+a8sCAKWsrKSmJar5QLLBarVCr1TAYDCguLmbdmWBwOp3o7+9Hc3NzWOuXaDCjXoLpZCKB2+3G8vIylpaWWP9dKBTi8OHDEAgEeO655xLlh28tSx4qGbSyssJmKkMRfGhoCFKpdNMJDqy1oqivr2dHA05PT8Plcl1l2ZhsZmNjY0oR3Gazsa5TrGeDzMxMlJeXo7y8HDabDQsLC/jOd74Dl8uF48ePJ/2gGYikk5xpIRHsjTGbzevaMASrrB8ZGUloUoWB/2hAf2VgVlYWSkpKMD8/j+rqas4633IBj8fD6mS4CpXm5eXB6XQiPz8fR48exfT0NG688UZO1uYKSSd5KFgsFnZOT7AxJoQQXLp0Cfn5+RtOad5s+Ff2mM1mDA8Ps1OPc3NzU8KSxyq62gharRaPPvoofve732Hnzp2crcslUpLk/mNMQhH8ypUryMzM3LD5TyJBCIFKpYJSqURVVdW6g5pCoUBJSUlSDp+M6EoikXDakdftdqO7uxvPPfdcyhIcSEGS22y2sGNMCCGYmJgARVHYsWNHSvl/09PT4PF4qK6uBkVR7NQ3t9sNjUaDvr4+5OTkQKlUQiwWJ2zvc3NzoCiK06JoQgieeuop3Hrrrbjttts4W3czkPToisfjYQ+cn332GSiKwu7du4OOMQHAjsROhbS4PxYWFmA0GsNmMwkhsFgsUKvVMJlMkEgkUCqVm1q3qdVq2TI/LjO4L7/8Mj7//HOcOHEiaQXg2GrRFYfDAbvdzvYDD0ZwRvexa9eulCK4VquFVqtldTShwAyNKiwsBE3TbN2m1+uFQqGAXC7n1J1ZXV1l21tzScTPPvsMb775Jj7++ONkEjxipIQlt9vt6OvrA03T6OrqYkd6+2N+fh4mkwnNzc0p9caaTCY2CxsrQV0uFzQaDZaWlpCXlwelUsl22o0VTIy+tbWV0zYQCwsLuPvuu3H69OmE9YQJg9RP6wNrh8zz589j586d7PQ2pVKJkpIStnxKpVJBq9UmtTdKMFgsFnYSMxetFgghWF1dhVqtxsrKChv7j5akPp8PFy9eRF1dHSdjIxnEqw3fBGwNkvf19a2bdeN2u6FWq7G8vIyCggJkZ2fDZDKllLAJWHOvBgYG0NLSsik+NdOGQq1Wg6Zp1p3ZqLsA0xKP6+QYTdN48MEHsX//fjz66KOcrRsntgbJ3W433G530CjKzMwMFhYWkJWVBYVCwbYrSzaYGUOhtOpcw+l0QqPRYHl5Gfn5+VAqlSFVgRMTEwCAuro6Tvdw5MgRLC4u4je/+U0qnYdSn+Q0TeOv/uqvcPPNN+Oee+5ZRxi9Xo/p6WlWeqvRaKDRaJCTk4PS0tK4fdZY4fP52BEsEokkodcmhMBsNkOtVsNsNkMmk0GpVLJ1q0zLO6716h988AGOHj2KP/7xjylhZPyQ+iQH1j6Y//qv/8LJkyfR2tqKnp4eeDwe8Hg87NmzZ92byvisTPGBXC6HUqlMWOsxpv0zc91kwufzQavVQq1WAwAKCwthNBrR1dXFqVs3NjaG7u5ufPjhh5DLI5oNm0hsDZIzoGkaZ86cwXPPPYfR0VE89thjeOCBB0IWPni9XiwvL0OtVkMgELCjUTbrYMrICPLy8lBVVbUp14gVRqMRw8PDyMjIQFFREZRKJSdDuhht+LFjx8Lq/JOIrUVyYI1IP/zhD/HUU0/ho48+whtvvIEdO3bggQcewPXXXx+SwFarFSqVCkajERKJBKWlpZx3T52YmABN06ivr08lnxQejwcXL15EU1MTCgoKsLKyArVazXbFVSgUMbXh8Hq9uOeee3D//ffj3nvv3YSdc4KtR/JA0DSNs2fP4tixYxgaGsJdd92F++67L+Rtk6Zp9hZOCIFSqeSk9cT8/DzMZjN2796dUgSnaRr9/f0oLy+/qszM6/Wy7wVFUVG9F4QQ/PKXvwSfz8fhw4fjfs0+nw9dXV0oLS3F6dOnMTMzg0OHDsFgMKCzsxOvvfZarL7+1ie5P0wmE15//XW89tprUCgU6OnpwU033RTyQ3M4HFCpVNDpdBCJRCgtLY1Jfbe0tAS1Ws1pLxIuwIiucnNzN3Sf7HY7NBoNtFot684wg3mD4eTJk/jv//5vvPvuu5z490eOHMGFCxewurqK06dP4+DBg7jzzjtx6NAhPPLII2htbY01LLm9SM5ugBBcuHABx44dw7lz5/C9730P999/f8iuSkxxg0qlgsfjYdWAkXSzNRqNbKfZVOl+y2Bubg42my0qDQ8zrVmtVsNqtbIFzP4H94GBAfzoRz/CmTNnONHCLy4uoru7Gz//+c9x5MgR/O///i872VogEODcuXP45S9/iQ8++CCW5beWdiVSUBSFPXv2YM+ePbBYLPjd736HBx54AAUFBejp6cF3vvOddel1/+IGl8sFtVqNCxcuoKCgAGVlZSEbC62urmJ8fDyl2jsz0Ol00Ov1aG9vj8qV8J9ZxLThGB4eBp/Ph1AoBJ/PxyOPPIKTJ09yVuzxxBNP4IUXXoDFYgGwVqsrFArZ9zSWBp7RInXuvzGgoKAADz/8MP70pz/h+eefx2effYZvfOMb+MUvfsEOcvJHVlYWqqursW/fPigUCszPz6O3txfz8/Ns1wDgq8GwLS0tKdMclIHFYsHU1BRaWlricp8yMjLYft8NDQ3o7e3F/v37UVFRwdm54/Tp05DJZEmPzKSWiYoRFEWhpaUF//qv/wqHw4G3334b//AP/wAej4f7778fd9xxxzqyBlo0jUaD/v5+5OTkQC6XY3p6OurBsImAy+XCyMgIWlpaOFUr5ubm4ty5c/jHf/xHdHV1wW63c7Lu2bNn8e677+K9996D0+nE6uoqHn/8caysrMDr9UIgEMTUwDNabDmfPFIQQjA+Po5jx47h//7v/3DTTTehp6cHDQ0NQS0V468yXbRKS0uv8leTCSbTWltby2kXXGBNG37u3Dm8/vrrm3a4/uSTT/Av//IvOH36NO6++24cOHCAPXi2tLTg7//+72NZdnsePGOB2+3GqVOn8Morr8But+Nv/uZvcOedd66z1ExbC6anCpNoysjIQGlpKcRicdKiK0wXXLFYzLnV++yzz/CLX/wCH3/88abeufxJPj09jUOHDsFoNKK9vR0nTpyI1S1MkzwQhBDMzs7ilVdewalTp/D1r38dDzzwAJqamnD+/HkolcqriqL9E02xSl/jhf8odC6xsLCAu+66C3/4wx9SQRseC9IkDwev14v33nsPL7/8MtuZ66WXXgoZS2ekr0wkoLS0dNMGUvljs0RXjDb8hRdewLe+9S3O1k0w0iSPBO+88w7eeustNDc34+2330ZHRwd6enrQ1dUV0j1hepzrdDoUFxejtLR0U9pOMFVHnZ2dnH6ZUlQbHgvSJI8EzKQLZpjWmTNn8J//+Z+YnZ3FPffcg3vvvTdkdU1gokmpVEZU2BAJ7HY7BgcH0d7ezvnhN0W14bEgTfJ4oNVqcfz4cbz55ptoaGhAT08PvvGNb4S07v6FDcxArlgnWHg8HrYoo7CwMN6Xsg4prA2PBWmScwFmctnLL7+MkZER3H333fjBD34Qsu82E4pUqVSw2+1sRVOkcW0mylNWVsZ5b+8U14bHgjTJuYbRaMSJEydw4sQJlJeXo6enBzfeeGNIf5npkajRaJCbm4vS0tKwzeyZzmDZ2dmcdwbbAtrwWJAm+WaBpmmcP38eL7/8Mr744gt8//vfxw9/+MOQ1UL+FU2rq6tsZVFgbHh+fh4WiwVNTU2c+spbRBseC1Kb5O+//z4ef/xx+Hw+PPzww3jmmWe4WjqhWF1dxVtvvYVXX30VIpEIPT09+Mu//MuQ7onX62Wtu3+iyWAwYH5+nvNOV1xrw1MMqUtyn8+H+vp6fPjhh6xI6M0330RTUxMXyycFzPydY8eO4dNPP8Wtt96K7u5uVFZWhiQW0zJOr9fD6/Wira2N8+p/rrXhKYbUJXmghvjw4cMAgJ/+9KdcLJ90OBwOnDx5Er/97W+RlZWF7u5u3HrrrUFT1y6XC319fVAoFDAYDADWEk0ymSxui861NjwFERHJkyLGUKlU65rmJ0JTnEjk5OSgu7sbn3zyCY4ePYq+vj5885vfxM9+9jOMjY2xEmCfz4ehoSE0NDSgqqoKnZ2daGxshMViwRdffIGxsTFYrdaY9qDVavHII4/gjTfe2K4EjxhbWk+e6qAoCo2NjXjxxRdx8eJFXHfddXj66adx66234sSJE/inf/onyGSydarC3Nxc1NXVYd++fRCJRJiYmMD58+ehUqng9Xojui7TN/zw4cNx9w1fWFjA/v370dTUhF27duHo0aMA1iJNN998M+rq6nDzzTfDZDLFdZ3NRNpdSTAIIZienkZPTw90Oh3279+PBx54IGynXqfTybbO22hUOiEETzzxBGprazk5zDNNnTo6OmCxWNDZ2Ynf//73ePXVV1FcXIxnnnkGv/rVr2AymfD888/Hfb0oEXndXxQ/nMDj8ZDq6moyPT1NXC4XaWlpISMjI1wtn/JwOBzkJz/5CXE4HOR//ud/yG233Uauu+468u///u9keXmZ2Gy2oD9Wq5XMz8+Tc+fOkTNnzpDLly+TlZWVdY85evQoOXToEPH5fJuy9zvuuIP88Y9/JPX19UStVhNCCFGr1aS+vn5TrrcBIuJt0kKI7733Hp544gn4fD48+OCD+PnPf87V0lsSi4uL+O1vf4t33nkHXV1d6OnpQUdHR0jrzkyv0Gg0yMvLQ25uLlQqFZ599tlN04bPzs7ihhtuwMjICCoqKrCysgJgzVCKRCL29wQidS15GqHh9XrJ+++/Tw4cOEC6urrIiy++SFQqVVjrrlKpyGOPPUaKi4vJ008/TUwmE+f7slgspKOjg7zzzjuEEEKKiorW/btQKOT8mhEgIt6mD54pBj6fj1tuuQVvv/02Tp8+DY/Hg9tuuw1/+7d/i7Nnz14165SiKGRkZOD8+fM4ceIEamtrWWUlV/B4PDhw4ADuu+8+3HnnnQAAuVwOjUYDYM1v51pnwyXSaf0tAJqm8emnn+LYsWO4fPkyDh48iHvvvRdSqXTTteGEEHR3d6O4uBgvvfQS+/ennnoKYrGYPXgajUa88MILnF9/A6RuMiiN2GEwGFiRWGVlJQoKCpCVlbVp2vDPPvsM3/zmN9eNsXnuueewb98+HDx4EPPz86isrMTJkyc5L7COANe2Tz4/P09uvPFG0tjYSJqamshLL71ECCHEYDCQb3/722THjh3k29/+NjEajUneaWzw+Xzk7Nmz5Fvf+hZxOp3J3k6ykNrRlc1Gisd30+AGqZvWTwQUCgU6OjoArHXaamxshEqlwqlTp9Dd3Q0A6O7uxu9///tkbjONBGDbWnJ/pGB8Nw1ucG1bcgZWqxUHDhzASy+9dFW9ZLCBuGlsP2xrkm/1+G4a3GDbkpwQgoceegiNjY348Y9/zP79jjvuwPHjxwEAx48fx1//9V8na4tpJAjb1idP8fhuGtwgnQxKY9sjffBMIw0gTfI0rgGkSZ7Gtke0JKfSP5H9UBQloChqgKKoP3z5ew1FUb0URU1RFHWSoqisJO3ruxRFjX+5j58m+32K8ycipC355uFxAJf9fn8ewK8JITsAmAA8lOgNURTFB/DvAL4LoAnAvRRFbd1mNxEiTfJNAEVRZQBuA/Dyl79TAP4CwNtfPuQ4gO8lYWt7AUwSQqYJIW4AbwHY9omCNMk3By8B+AkApoxHDGCFEML0lFgEsLkjz4KjFMCC3+/J2kdCkSY5x6Ao6nYAWkLIxWTvJY01bIs5nimGbwC4g6KoWwFkAygEcBSAkKIowZfWvAxAMlqGqQCU+/2erH0kFGlLzjEIIT8lhJQRQqoAHAJwhhByH4D/D8BdXz6sG8CpJGzvPIA6iqKqKYrK/HJ/7yZhHwlFmuSJw9MAfkxR1CTWfPRXEr2BL+8iPwLwAdYiPycJIaOJ3keiEa12JY00thzSljyNbY80ydPY9vj/Ab6hGJaEkxwjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "affine_objectives = [\n",
    "    {'rot': [math.pi/6, math.pi/6, 0],\n",
    "     'trans': [.1, .1, 0]},\n",
    "    {'rot': [-math.pi/6, -math.pi/6, -math.pi/6],\n",
    "     'trans': [-.1, -.1, -.1]},\n",
    "]\n",
    "get_affine_matrix\n",
    "\n",
    "modelnet_path = './data/ModelNet10'\n",
    "categories = ['dresser']\n",
    "trainset = ModelNetVoxels(modelnet_path, categories=categories, resolutions=[32],\n",
    "                                         split='train', device=device)\n",
    "train_loader = DataLoader(trainset, batch_size=1)\n",
    "batch = next(iter(train_loader))\n",
    "x = batch['data']['32'][0, :, :, :].to(device).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "visualize_affine_opt(x, affine_objectives, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization with Random Restarts\n",
    "Above results show that differentiable optimization works resonably well, but inconsistently:\n",
    "* Better for simple shapes (dresser vs. table)\n",
    "* Better for translations than rotations\n",
    "* Limited to smaller rotations (<45 degrees)\n",
    "\n",
    "Because of this we need to use another method to ensure the optimization isn't caught in a local optimum. \n",
    "\n",
    "Note there's a bunch of better ways to do optimization, but we choose something simple. We want it to be easily parallelizable. It's relatively fast to a forward pass on a bunch of parameters, but slow to do things sequentially. So we'll randomly sample n_rand parameters, and do SGD on the top n_sgd of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "converting to voxels to resolution 32: 100%|██████████| 200/200 [00:00<00:00, 31784.66it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f27fe9c59c8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maffine_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maffine_dict\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maffine_objectives\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'32'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mx_pad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaolin/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaolin/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaolin/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaolin/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaolin/lib/python3.6/site-packages/kaolin-0.1.0-py3.6-linux-x86_64.egg/kaolin/datasets/modelnet.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'resolutions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_transforms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0mattributes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mattributes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat_idxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaolin/lib/python3.6/site-packages/kaolin-0.1.0-py3.6-linux-x86_64.egg/kaolin/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, object_id, inp)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcached_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mtransformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtransformed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaolin/lib/python3.6/site-packages/kaolin-0.1.0-py3.6-linux-x86_64.egg/kaolin/transforms/transforms.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(self, fpath)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m'format'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mmatrix_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'format'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0msparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsc_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'indices'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'indptr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'shape'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaolin/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    260\u001b[0m                 return format.read_array(bytes,\n\u001b[1;32m    261\u001b[0m                                          \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_pickle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                                          pickle_kwargs=self.pickle_kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaolin/lib/python3.6/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m     \u001b[0mversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0m_check_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m     \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfortran_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_array_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaolin/lib/python3.6/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36m_read_array_header\u001b[0;34m(fp, version)\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;31m# Sanity-check the values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m     if (not isinstance(d['shape'], tuple) or\n\u001b[0;32m--> 609\u001b[0;31m             not numpy.all([isinstance(x, (int, long)) for x in d['shape']])):\n\u001b[0m\u001b[1;32m    610\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"shape is not valid: {!r}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'shape'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaolin/lib/python3.6/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;31m# Sanity-check the values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m     if (not isinstance(d['shape'], tuple) or\n\u001b[0;32m--> 609\u001b[0;31m             not numpy.all([isinstance(x, (int, long)) for x in d['shape']])):\n\u001b[0m\u001b[1;32m    610\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"shape is not valid: {!r}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'shape'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "categories = ['dresser', 'desk', 'night_stand',  'bathtub', 'chair', \n",
    "                   'sofa', 'monitor', 'table', 'toilet', 'bed']\n",
    "\n",
    "results = pd.DataFrame()\n",
    "affine_objectives = [\n",
    "    {'rot': [0, 0, 0],\n",
    "     'trans': [0, 0, 0]},\n",
    "    {'rot': [math.pi/6, 0, 0],\n",
    "     'trans': [.2, 0, 0]},\n",
    "    {'rot': [-math.pi/4, -math.pi/4, -math.pi/4],\n",
    "     'trans': [-.2, -.2, -.2]},\n",
    "]\n",
    "\n",
    "for n_affine in [4, 16, 64, 256]:\n",
    "    for category in categories:\n",
    "        trainset = ModelNetVoxels(modelnet_path, categories=[category], resolutions=[32],\n",
    "                                   split='train', device=device)\n",
    "        train_loader = DataLoader(trainset, batch_size=1)\n",
    "        category_results = {}\n",
    "        category_results['category'] = category\n",
    "        for affine_idx, affine_dict in enumerate(affine_objectives):\n",
    "            total_loss = 0\n",
    "            for batch in train_loader:\n",
    "                x = batch['data']['32'][0, :, :, :].to(device).unsqueeze(0).unsqueeze(0)\n",
    "                x_pad = pad_3d(x, pad_factor=1.5).detach()\n",
    "                x_goal = affine_transform(x_pad, affine_mat=get_affine_matrix(**affine_dict))\n",
    "                loss, affine_params = rand_opt(x_pad, x_goal, n_affine=n_affine)\n",
    "                total_loss += loss.item()\n",
    "            category_results[affine_idx] = total_loss/len(train_loader)\n",
    "        results = results.append(category_results, ignore_index=True)\n",
    "    print(f'{n_affine} random restarts, average loss: {np.mean(results.values[:, :3])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Restarts + SGD\n",
    "* Above result shows random restarts is working.\n",
    "* Do gradient descent on the best random restarts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_sgd_opt(x, x_goal, n_sgd=4, n_total_affine=16):\n",
    "    \"\"\" BS=1 !\n",
    "    n_affine is number of random restarts\n",
    "    \"\"\"\n",
    "    bs, ch, _, _, _ = x.size()\n",
    "    assert bs==1\n",
    "    r_init = torch.ones([n_total_affine, 3], dtype=torch.float32, device=x.device).uniform_(0, 2*math.pi)\n",
    "    t_init = torch.ones([n_total_affine, 3], dtype=torch.float32, device=x.device).uniform_(-.2, .2)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        affine_params = make_affine(r=r_init, t=t_init, device=x.device)\n",
    "        \n",
    "        # repeat in batch dim, so bs*n_affine:\n",
    "        x_rep = x.repeat(n_total_affine, 1, 1, 1, 1)\n",
    "        xg_rep = x_goal.repeat(n_total_affine, 1, 1, 1, 1)\n",
    "\n",
    "        # \"forward pass\", and sum loss per example\n",
    "        x_affine = affine_transform(x_rep, affine_params)\n",
    "        loss = F.mse_loss(x_affine, xg_rep, reduction='none')\n",
    "        loss = loss.sum((-3, -2, -1)).squeeze()\n",
    "        best_loss, best_param_idx = torch.topk(loss, k=n_sgd, largest=False)\n",
    "        \n",
    "    # SGD TIME - Select best params and get rid of old params so no grad or memory issues\n",
    "    del x_affine, x_rep, xg_rep\n",
    "    r_init = r_init[best_param_idx, :].clone().detach().requires_grad_(True)\n",
    "    t_init = t_init[best_param_idx, :].clone().detach().requires_grad_(True)\n",
    "    \n",
    "    x_rep = x.repeat(n_sgd, 1, 1, 1, 1)\n",
    "    xg_rep = x_goal.repeat(n_sgd, 1, 1, 1, 1)\n",
    "    optimizer = optim.Adam([r_init, t_init], lr=.01)\n",
    "\n",
    "    for i in range(25):\n",
    "        affine_params = make_affine(r=r_init, t=t_init, device=x.device)\n",
    "        x_affine = affine_transform(x_rep, affine_params)        \n",
    "        loss = F.mse_loss(x_affine, xg_rep, reduction='sum')\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    loss = F.mse_loss(x_affine, xg_rep, reduction='none')\n",
    "    loss = loss.sum((-3, -2, -1)).squeeze()\n",
    "    best_loss, best_param_idx = torch.min(loss, dim=0)\n",
    "#     print('final best loss: ', best_loss.item())\n",
    "    return best_loss, affine_params[best_param_idx, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "converting to voxels to resolution 32: 100%|██████████| 2275/2275 [00:00<00:00, 30464.44it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-9b58a403f7d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mx_pad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mx_goal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maffine_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maffine_mat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_affine_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0maffine_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maffine_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrand_sgd_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_goal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_sgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_sgd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_total_affine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_total_affine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                 \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_sgd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_total_affine\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-c7139076e4a1>\u001b[0m in \u001b[0;36mrand_sgd_opt\u001b[0;34m(x, x_goal, n_sgd, n_total_affine)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_affine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxg_rep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_affine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxg_rep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'none'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaolin/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaolin/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time."
     ]
    }
   ],
   "source": [
    "affine_objectives = [\n",
    "    {'rot': [0, 0, 0],\n",
    "     'trans': [0, 0, 0]},\n",
    "    {'rot': [math.pi/6, 0, 0],\n",
    "     'trans': [.2, 0, 0]},\n",
    "    {'rot': [-math.pi/4, -math.pi/4, -math.pi/4],\n",
    "     'trans': [-.2, -.2, -.2]},\n",
    "]\n",
    "\n",
    "__BS = 4\n",
    "\n",
    "categories = ['dresser', 'desk', 'night_stand',  'bathtub', 'chair', 'sofa', ]#'monitor', 'table', 'toilet', 'bed']\n",
    "trainset = ModelNetVoxels(modelnet_path, categories=categories, resolutions=[32],\n",
    "                           split='train', device=device)\n",
    "train_loader = DataLoader(trainset, batch_size=__BS)\n",
    "\n",
    "n_sgd_list = [2, 4, 8, 16]\n",
    "n_total_affine_list = [16, 32, 64]\n",
    "results = pd.DataFrame(columns=n_sgd_list, index=n_total_affine_list)\n",
    "\n",
    "for n_total_affine in n_total_affine_list:\n",
    "    for n_sgd in n_sgd_list:\n",
    "        if n_total_affine < n_sgd: \n",
    "            continue\n",
    "            \n",
    "        total_loss = 0\n",
    "        for affine_idx, affine_dict in enumerate(affine_objectives):\n",
    "            for batch in train_loader:\n",
    "                x = batch['data']['32'][0, :, :, :].to(device).unsqueeze(0).unsqueeze(0)\n",
    "                x_pad = pad_3d(x, pad_factor=1.5).detach()\n",
    "                x_goal = affine_transform(x_pad, affine_mat=get_affine_matrix(**affine_dict))\n",
    "                loss, affine_params = rand_sgd_opt(x_pad, x_goal, n_sgd=n_sgd, n_total_affine=n_total_affine)\n",
    "                total_loss += loss.item()\n",
    "        results.at[n_sgd, n_total_affine] = total_loss/len(train_loader)\n",
    "        print(f'Inits: {n_total_affine}, SGD on top {n_sgd}, average loss: {total_loss/len(train_loader)}')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_sgd_opt_batch(x, x_goal, n_sgd=4, n_total_affine=16):\n",
    "    \"\"\"\n",
    "    n_affine is number of random restarts\n",
    "    \"\"\"\n",
    "    bs, ch, _, _, _ = x.size()\n",
    "    r_init = torch.ones([n_total_affine, 3], dtype=torch.float32, device=x.device).uniform_(0, 2*math.pi)\n",
    "    t_init = torch.ones([n_total_affine, 3], dtype=torch.float32, device=x.device).uniform_(-.2, .2)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        affine_params = make_affine(r=r_init, t=t_init, device=x.device)\n",
    "        \n",
    "        # repeat in batch dim, so bs*n_affine:\n",
    "        x_rep = x.repeat(n_total_affine, 1, 1, 1, 1)\n",
    "        xg_rep = x_goal.repeat(n_total_affine, 1, 1, 1, 1)\n",
    "        affine_params_rep = affine_params.repeat(bs, 1, 1).view(bs*n_total_affine, 3, 4).to(x.device)\n",
    "        \n",
    "        # \"forward pass\", and get loss per example\n",
    "        x_affine = affine_transform(x_rep, affine_params_rep)\n",
    "        loss = F.mse_loss(x_affine, xg_rep, reduction='none')\n",
    "        loss = loss.sum((-3, -2, -1)).squeeze()\n",
    "        loss = loss.view(n_total_affine, bs)\n",
    "        \n",
    "        best_loss, best_param_idx = torch.topk(loss, dim=0, k=n_sgd, largest=False)\n",
    "        affine_params_rep = affine_params_rep.view(n_total_affine, bs, 3, 4)\n",
    "        best_affine_params = affine_params_rep[best_param_idx, torch.arange(bs), :, :]\n",
    "        best_affine_params = best_affine_params.view(n_sgd*bs, 3, 4)\n",
    "        \n",
    "    # SGD TIME - Get rid of old params and re-create so no grad or memory issues\n",
    "    affine_params = best_affine_params.clone().detach().requires_grad_(True)\n",
    "    del best_affine_params, x_affine, x_rep, xg_rep, r_init, t_init\n",
    "    x_rep = x.repeat(n_sgd, 1, 1, 1, 1)\n",
    "    xg_rep = x_goal.repeat(n_sgd, 1, 1, 1, 1)\n",
    "    optimizer = optim.Adam([affine_params], lr=.03)\n",
    "\n",
    "    for i in range(20):\n",
    "        x_affine = affine_transform(x_rep, affine_params)        \n",
    "        loss = F.mse_loss(x_affine, xg_rep, reduction='sum')\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    loss = F.mse_loss(x_affine, xg_rep, reduction='none')\n",
    "    loss = loss.sum((-3, -2, -1)).squeeze()\n",
    "    best_loss, best_param_idx = torch.min(loss, dim=0)\n",
    "    return best_loss, affine_params[best_param_idx, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "converting to voxels to resolution 32: 100%|██████████| 2275/2275 [00:00<00:00, 29641.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 32, 32, 32]) torch.Size([3, 1, 48, 48, 48])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor to have size 3 at dimension 0, but got size 4 for argument #2 'batch2' (while checking arguments for bmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-c24d692f6f28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_pad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0maffine_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_affine_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0maffine_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0mx_goal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maffine_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maffine_mat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maffine_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maffine_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrand_sgd_opt_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_goal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_sgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_sgd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_total_affine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_total_affine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/disentangled-3d/utils_3d.py\u001b[0m in \u001b[0;36maffine_transform\u001b[0;34m(x, affine_mat, padding_mode)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0maffine_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maffine_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'zeros'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maffine_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maffine_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign_corners\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign_corners\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaolin/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36maffine_grid\u001b[0;34m(theta, size, align_corners)\u001b[0m\n\u001b[1;32m   2797\u001b[0m                          .format(size))\n\u001b[1;32m   2798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2799\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maffine_grid_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign_corners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor to have size 3 at dimension 0, but got size 4 for argument #2 'batch2' (while checking arguments for bmm)"
     ]
    }
   ],
   "source": [
    "affine_objectives = [\n",
    "    {'rot': [0, 0, 0],\n",
    "     'trans': [0, 0, 0]},\n",
    "    {'rot': [math.pi/6, 0, 0],\n",
    "     'trans': [.2, 0, 0]},\n",
    "    {'rot': [-math.pi/4, -math.pi/4, -math.pi/4],\n",
    "     'trans': [-.2, -.2, -.2]},\n",
    "]\n",
    "\n",
    "bs = 4\n",
    "\n",
    "categories = ['dresser', 'desk', 'night_stand',  'bathtub', 'chair', 'sofa', ]#'monitor', 'table', 'toilet', 'bed']\n",
    "trainset = ModelNetVoxels(modelnet_path, categories=categories, resolutions=[32],\n",
    "                           split='train', device=device)\n",
    "train_loader = DataLoader(trainset, batch_size=bs)\n",
    "\n",
    "n_sgd_list = [2, 4, 8, 16]\n",
    "n_total_affine_list = [16, 32, 64]\n",
    "results = pd.DataFrame(columns=n_sgd_list, index=n_total_affine_list)\n",
    "\n",
    "for n_total_affine in n_total_affine_list:\n",
    "    for n_sgd in n_sgd_list:\n",
    "        if n_total_affine < n_sgd: \n",
    "            continue\n",
    "        total_loss = 0\n",
    "        for affine_idx, affine_dict in enumerate(affine_objectives):\n",
    "            for batch in train_loader:\n",
    "                x = batch['data']['32'].to(device).unsqueeze(1)\n",
    "                x_pad = pad_3d(x, pad_factor=1.5).detach()\n",
    "                if x_pad.size() != torch.Size([bs, 1, 48, 48, 48]):\n",
    "                    print(x.size(), x_pad.size())\n",
    "                affine_mat = get_affine_matrix(**affine_dict).repeat(bs, 1, 1)\n",
    "                x_goal = affine_transform(x_pad, affine_mat=affine_mat)\n",
    "                loss, affine_params = rand_sgd_opt_batch(x_pad, x_goal, n_sgd=n_sgd, n_total_affine=n_total_affine)\n",
    "                total_loss += loss.item()\n",
    "        results.at[n_sgd, n_total_affine] = total_loss/len(train_loader)\n",
    "        print(f'Inits: {n_total_affine}, SGD on top {n_sgd}, average loss: {total_loss/len(train_loader)}')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaolin",
   "language": "python",
   "name": "kaolin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
